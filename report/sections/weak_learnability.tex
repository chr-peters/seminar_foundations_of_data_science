\section{Weak Learnability}

Assuming that the realizable assumption~\cite[chapter 2]{SSBD14} holds, the generalization error
$L_{(\mathcal{D}, f)}(h)$ of a PAC learner with respect to a distribution $\mathcal{D}$ and a
labeling function $f$ can by the definition of PAC learning~\mbox{\cite[chapter 2]{SSBD14}} be reduced to an arbitrarily
small number (with confidence of $1-\delta$) by increasing the sample size of the training sequence $S$.
This, however, can be computationally infeasible in practical applications.

The concept of weak learnability aims to relax the requirement that the generalization error of a hypothesis must
become arbitrarily small the more the sample size is increased.
For weak learning, it is sufficient that the learning algorithm yields a hypothesis $h$, that performs only slightly
better than a random guess.
One can think of weak learning as applying a simple rule which isn't fully capable of modeling the data generating process,
but can still learn a little bit about the underlying problem so that it performs better than random.

Formally, the definition of a weak learner differs only slightly from the definition of PAC learning.
In the situation of a two-class classification problem, the definition of a weak learner, can be given as follows:

\begin{definition}{($\gamma$-weak-learner)}
\label{def:weak-learner}
An Algorithm $A$ is a $\gamma$-weak-learner for a hypothesis class $\mathcal{H}$ if for every $\delta \in (0, 1)$ there
exists a threshold $m_\mathcal{H}(\delta) \in \mathbb{N}$
such that for every distribution $\mathcal{D}$ over the instance space $\mathcal{X}$
and for every labeling function $f: \mathcal{X} \rightarrow \{\pm 1\}$ if running $A$ on $m \geq m_\mathcal{H}$ training
examples, it will yield a hypothesis $h$ such that with probability of at least $1-\delta$ the generalization error
$L_{(\mathcal{D}, f)}(h)$ is at most $\frac{1}{2} - \gamma$, provided that the realizable assumption holds.
\end{definition}

The parameter $\gamma$ in Definition \ref{def:weak-learner} tells us how well we can expect the weak learner to perform.
For example if a learning algorithm is a $1\%$-weak-learner for a class $\mathcal{H}$, then the generalization
error can at most be $49\%$ provided that first, the learner didn't fail
(which can happen with probability $\delta$ of drawing a bad sample from $\mathcal{D}$)
and second, the learner was run on at least $m_\mathcal{H}(\delta)$ training examples.

It still remains the question of how to obtain a weak learning algorithm for a class $\mathcal{H}$.
We already saw that applying the ERM rule to complex hypothesis classes can be computationally hard.
But what if we choose a simple hypothesis class $B$ instead, where the ERM rule can be applied efficiently?
It follows directly from Definition~\ref{def:weak-learner} that this can only work if the new algorithm
$\text{ERM}_B$ has an error of at most $\frac{1}{2} - \gamma$ for every sample that was labeled by a hypothesis from
$\mathcal{H}$. In this case, applying the ERM rule with respect to the simpler class $B$ would yield a weak learner
for $\mathcal{H}$.

\subsection{An Efficient ERM Algorithm for Decision Stumps}

One such hypothesis class, where the ERM algorithm can be implemented efficiently, is the class of decision stumps.
On the instance space $\mathcal{X} = \mathbb{R}^d$,  this class is given as follows:
\begin{linenomath}
\begin{equation*}
    \mathcal{H}_{DS} = \{ \mathbf{x} \mapsto \text{sign}\left( \theta - x_i \right) \cdot b: \ 
        \theta \in \mathbb{R}, i \in \left[ d \right], b \in \{ \pm 1 \} \}
\end{equation*}
\end{linenomath}

The idea behind decision stumps is to divide the instance space $\mathcal{X}$ along one of its dimensions
$i \in \left[ d \right]$ at a threshold $\theta$ into two partitions, 
such that all the instances in one partition are labeled
$+1$ and all the instances in the other partition are labeled $-1$.
An ERM algorithm for $\mathcal{H}_{DS}$ has to find the optimal splitting dimension $i \in \left[ d \right]$ as well
as the optimal splitting threshold $\theta$ such that the training error $L_S(h)$ on a training sequence
$S = \left( (\mathbf{x}_1, y_1),...,(\mathbf{x}_m, y_m) \right)$ is minimized.

Let $b=1$ without the loss of generality. Then the $\text{ERM}_{\mathcal{H}_{DS}}$ algorithm has to solve
the following optimization problem that minimizes the sum of misclassifications:
\begin{linenomath}
\begin{equation*}
    \min_{j \in \left[ d \right]} \  \min_{\theta \in \mathbb{R}} \ 
        \left( \sum_{i: y_i=1}^m \mathds{1}_{\left[ x_{i, j} > \theta \right]} + 
            \sum_{i: y_i=-1}^m \mathds{1}_{\left[ x_{i, j} \leq \theta \right]} \right)
\end{equation*}
\end{linenomath}
Taking a closer look at this problem it becomes clear, that it is not necessary to try every $\theta \in \mathbb{R}$
during the optimization.
In fact, if we first sort the examples for a fixed dimension $j \in \left[ d \right]$ so that
$x_{1, j} \leq x_{2, j} \leq ... \leq x_{m, j}$, we can see that we only have to consider a single splitting 
threshold in between two examples, which leaves us with $m+1$ values for $\theta$ that the 
$\text{ERM}_{\mathcal{H}_{DS}}$ hat to consider for a fixed dimension $j \in \left[ d \right]$.
Since the sum of misclassifications can be computed in $\mathcal{O}(m)$ by passing through the data once,
the algorithm can find optimal values for $j$ and $\theta$ in $\mathcal{O}(dm^2)$ by simple enumeration.

This time complexity can be reduced even more by avoiding to recalculate the sum of misclassifications for
every new value of $\theta$. It can be shown~\cite{SSBD14} that it is possible to update the sum for a new
value of $\theta$ in constant time, requiring only a single pass through the data for a fixed dimension $j$.
This leaves us with a time complexity of $\mathcal{O}(dm)$ of solving the optimization problem after the sorting
step is applied as preprocessing.
