\section{AdaBoost}
\label{sec:adaboost}

In the previous section, it was demonstrated how an efficient weak learner can be constructed by applying the ERM rule to
the class of decision stumps.
This section presents the AdaBoost (Adaptive Boosting) algorithm, a procedure that shows 
how weak learners such as decision stumps can be
used efficiently to find a hypothesis with an arbitrarily low empirical error $L_S(h)$ on a training sequence $S$.
The AdaBoost algorithm was first proposed in 1995 by Yoav Freund and Robert Schapire~\cite{FREUND1997119}
and became hugely popular due to its practicability.

The goal of AdaBoost is to invoke the weak learner multiple times on the training data and then to combine
the resulting hypotheses similar to a weighted majority vote.
Let $T$ be the number of times that the weak learner is invoked by AdaBoost. Then the resulting
output hypothesis of AdaBoost has the following form:
\begin{linenomath*}
    $$
    h(x) = \text{sign}\left( \sum_{t=1}^T w_t h_t(x) \right)
    $$
\end{linenomath*}
Here, $h_t(x)$ is the output hypothesis of the weak learner in iteration $t$ and $w_t$ is the corresponding weight
that AdaBoost assigns to this hypothesis.

In the first iteration $t=1$, the AdaBoost algorithm assigns an equal weight $D_i^{(1)} = \frac{1}{m}$ to each example
in the training sequence $S$ and then invokes the weak learner on the weighted training sequence.
The error of the resulting hypothesis is computed according to
\begin{linenomath*}
    $$
    \epsilon_t = \sum_{i=1}^m D_i^{(t)} \mathds{1}_{\left[ h_t(\mathbf{x}_i) \neq y_i \right]}
    $$
\end{linenomath*}
and is at most $\frac{1}{2}-\gamma$, provided that the weak learner didn't fail.

The weight $w_t$ that is assigned to a hypothesis in boosting round $t$ is computed as follows:
\begin{linenomath*}
    $$
    w_t = \frac{1}{2} \text{log} \left( \frac{1}{\epsilon_t} - 1 \right)
    $$
\end{linenomath*}
As we can see, the smaller the error $\epsilon_t$ of the hypothesis $h_t$ is, the bigger the weight $w_t$ will be.

At the end of each iteration, the weights $D_i^{(t)}$ of each training example are updated according to
\begin{linenomath*}
    $$
    D_i^{(t+1)} = \frac{D_i^{(t)} \text{exp} \left( -w_t y_i h_t(\mathbf{x}_i) \right)}{
        \sum_{j=1}^m D_j^{(t)} \text{exp} \left( -w_t y_j h_t(\mathbf{x}_j) \right) }
    $$
\end{linenomath*}
This update assigns a higher weight to those examples, that weren't correctly classified by $h_t$.

In short, the Adaboost algorithm performs the following steps in each of the $T$ iterations:
\begin{enumerate}
    \item Invoke the weak learner on the training sequence $S$ weighted by $\mathbf{D}^{(t)}$
    \item Assign a weight $w_t$ to the output hypothesis $h_t$ of the weak learner. Hypotheses with a smaller
        training error $\epsilon_t$ will get a higher weight.
    \item Compute a new weight vector $\mathbf{D}^{(t+1)}$ that gives a higher weight to incorrectly classified
        examples.
\end{enumerate}

The computational complexity of AdaBoost essentially consists of invoking the weak learning algorithm $T$ times on
the training data. Thus, if the weak learner can be implemented efficiently (as it is the case for decision stumps),
AdaBoost is also efficient.

On top of that, it can be shown~\cite{SSBD14}, 
that the training error $L_S(h)$ of the AdaBoost hypothesis $h$ decreases exponentially
in the number of boosting rounds $T$:
\begin{linenomath*}
    $$
    L_S(h) = \frac{1}{m} \sum_{i=1}^m \mathds{1}_{\left[ h(\mathbf{x}_i) \neq y_i \right]} \leq e^{-2 \gamma^2 T}
    $$
\end{linenomath*}
Here, $\gamma$ describes the $\gamma$-weak-learner as defined in Definition~\ref{def:weak-learner}.
This means that, by increasing the number of boosting rounds $T$,  AdaBoost will achieve an arbitrarily low training
error and is still an efficient algorithm.

In practical applications however, it is more important to also achieve a good out of sample error. The next section will
show that the true risk $L_\mathcal{D}(h)$ of the AdaBoost hypothesis will also be small by taking a look at the
hypothesis class that resembles all the possible output hypotheses of AdaBoost.

\subsection{AdaBoost Out-of-Sample Performance}
\label{sec:vcdim}

The hypothesis class of AdaBoost is parameterized by the hypothesis class $B$ of the weak learner it uses as well as by
the number of boosting rounds $T$. Formally, it is given as follows:
\begin{linenomath*}
    $$
    L(B, T) = \left \{ x \mapsto \text{sign} \left( \sum_{t=1}^T w_t h_t(x) \right): \ 
        w \in \mathbb{R}^T, \  h_t \in B \right \}
    $$
\end{linenomath*}

The fundamental theorem of statistical learning~\cite[chapter 6]{SSBD14} states that a hypothesis class is PAC-learnable
if and only if its VC dimension is finite, i.e. there exists a threshold $m$, such that for every set with more than
$m$ elements there exists a labeling function that cannot be learned using that class.
This means that if the VC dimension of $L(B, T)$ is finite and thus $L(B, T)$ is PAC-learnable, then, by the definition
of PAC learning, there exists a threshold 
$m_\mathcal{H}(\epsilon, \delta) \in \mathbb{N}$ for every $\epsilon, \delta \in (0, 1)$, 
such that the true error $L_\mathcal{D}(h)$ of the AdaBoost hypothesis $h \in L(B, T)$ is at most $\epsilon$
(with confidence $1-\delta$)
for every distribution $\mathcal{D}$ when training AdaBoost on at least $m_\mathcal{H}(\epsilon, \delta)$ training
examples. This tells us that if $L(B, T)$ is learnable, even the Out-of-Sample error of AdaBoost can be reduced
arbitrarily (if the realizable assumption holds), by increasing the amount of training examples.

It can be shown~\cite{SSBD14} that an upper bound of the VC dimension of $L(B, T)$ 
is linear in the VC dimension of the hypothesis
class $B$ of the weak learner and also linear in $T$, i.e. $\text{VCdim}(L(B, T))$ is in
$\mathcal{O}(\text{VCdim}(B) \cdot T)$.
This means that if the VC dimension of $B$ is finite, so is the VC dimension of $L(B, T)$.

In the case of $B$ being the hypothesis class of all decision stumps, the VC dimension of $B$ is 2,
so it is clearly finite.
It follows from the fundamental theorem of statistical learning, that when using decision stumps as the hypothesis
class for the weak learner, AdaBoost is a PAC learner for the class $L(B, T)$.
Furthermore, if the weak learner for $B$ can be implemented efficiently (as we have shown for decision stumps), AdaBoost
is also efficient.

\subsection{The Expressive Power of L(B, T)}

In section~\ref{sec:vcdim}, we saw that the VC dimension of $L(B, T)$ grows linear in $T$ and in the VC dimension of
$B$. If $B$ is the class of decision stumps, it follows that the VC dimension
of $L(B, T)$ is in $\mathcal{O}(T)$, i.e. the expressive power of the class increases with the parameter $T$.
To demonstrate what that means, we can take a look how $L(B, T)$ can be used to learn the class of piece-wise constant
functions, with $B$ being the class of decision stumps.

The class of piece-wise constant functions on the line ($\mathcal{X} = \mathbb{R}$) is given as follows:
\begin{linenomath*}
    $$
    \mathcal{G}_r = \left \{ x \mapsto \sum_{i=1}^r \alpha_i \mathds{1}_{[x \in (\theta_{i-1}, \theta_i]]}: \ 
        \alpha_i \in \{\pm 1 \},\  -\infty = \theta_0 < \theta_1 < ... < \theta_r = \infty \right \}
    $$
\end{linenomath*}
Here, $\theta_i \in \mathbb{R}$ are the thresholds and $\alpha_i$ determines the constant label $+1$ or $-1$
for each area between two thresholds. We will now show, that $L(B, T)$ can be used to learn the class
of piece-wise constant functions with $T$ pieces $\mathcal{G}_T$.

\begin{theorem}
\label{thm:piece-wise}
\begin{linenomath*}
	Let $B$ be the class of decision stumps and $L(B, T)$ as defined above.
	Then $\mathcal{G}_T \subseteq L(B, T)$.
\end{linenomath*}
\end{theorem}
\begin{proof}
	Without loss of generality, let $g \in \mathcal{G}_T$ with $\alpha_t = (-1)^t$. We can assign the weight
	$w_1=-0.5$ to the first decision stump in $L(B, T)$ and for $t > 1$ we can assign the weights $w_t = (-1)^t$
	to the remaining decision stumps. If we choose $\theta_{t-1}$ as the $\theta$ parameter for decision
	tree $t$ and $b=-1$, we get the following hypothesis:
	$$
	    h(x) = \text{sign} \left( \sum_{t=1}^T w_t \  \text{sign} (x - \theta_{t-1}) \right) \in L(B, T)
	$$
	We can see that the first decision stump with threshold $\theta_{0}$ and weight $w_1 = -0.5$ predicts the
	constant value $-0.5$ for every $x \in \mathbb{R}$. The other trees mirror the change of $g$ for each threshold
	using the weights $w_t = (-1)^t$. It follows that if $g(x) = 1$, the weighted sum predicts $1.5$ and for
	$g(x) = -1$, the weighted sum predicts $-0.5$. Thus, it follows that $h(x) = g(x)\  \forall x \in \mathbb{R}$,
	which concludes the proof.
\end{proof}