\section{Introduction}

Training machine learning models in practice is not always as simple as it might seem from a theoretical standpoint.
In~\cite[chapter 2]{SSBD14}, the empirical risk minimization (ERM) rule was introduced as the learning algorithm
of choice.
However, this theoretical principle of choosing a hypothesis \mbox{$h \in \mathcal{H}$} such that
$L_S(h) = \min_{h \in \mathcal{H}} L_S(h)$, where $L_S(h)$ is the error of $h$ on the training sequence $S$,
can be impossible to use in practical applications due to the sometimes enormous computational complexity of searching
through interesting hypothesis classes $\mathcal{H}$.

This problem leads to the question if it is possible to arrive at a strong learning algorithm in a way that doesn't require the
computational cost of searching through complex hypothesis classes.
Is it perhaps possible to create a strong learner by finding a way to combine "weak" learners that are potentially easier to compute?
The algorithmic paradigm of boosting deals with exactly this question, 
which was first raised by Kearns and Valiant in 1988~\cite{kv-lbffahf-88}, 
resulting in the widely used AdaBoost algorithm that
shows how "weak" learners can be combined in order to obtain a strong learning algorithm.

The goal of this article is to first lay down the foundations of boosting by explaining the concept of weak 
learnability, which will be used to arrive at the AdaBoost algorithm, the first practical implementation of boosting.
