\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage{ngerman}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage[font=footnotesize]{caption}
\usepackage{amsthm,amsmath,amsfonts}
               
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
%\renewcommand{\proofname}{Beweis}

\usepackage{lineno}

               
\title{Boosting\\
	\emph{Seminar: Foundations of Data Science}}
\author{Christian Peters, enrolment no.: 213996\\
	Faculty of Statistics\\
	TU Dortmund}

\date{\today\\
	winter term 
	2020/21}

\begin{document}
\maketitle
\linenumbers
\begin{abstract}
A short summary of about two to three sentences that briefly and concisely outline the content \ldots
\end{abstract}

\section{%Einleitung
		Introduction}
This article deals with the fundamentals of data science. We are covering the topic XYZ in particular, which is very interesting and besides the theoretical depth has many practical applications.

We start with a definition, which plays a central role in this work.
\begin{definition}{%(Euklidische Norm)}
				(Euclidean norm)}
\begin{linenomath*}
	%Sei $x\in\mathbb{R}^d$ dann bezeichne $$\|x\|=\sqrt{\sum_{i=1}^{d} x_i^2}$$ die Euklidische Norm von $x$.
	Let $x\in\mathbb{R}^d$. We denote by $$\|x\|=\sqrt{\sum_{i=1}^{d} x_i^2}$$ the Euclidean norm of $x$.
\end{linenomath*}
\end{definition}
	
\section{Main Part}
\label{main_part}
Here we work with the above definitions and notations and derive important results such as the following Theorem on the least-squares solution

\begin{theorem}{(useful theorem)}
\label{thm:main}
\begin{linenomath*}
	%Seien $X\in\mathbb{R}^{n\times d}, Y\in\mathbb{R}^n$ und sei $\beta^* = \operatorname{argmin}_{\beta\in R^d}\|X\beta-Y\|^2$. Dann gilt $$\|Y\|^2=\|X\beta^*\|^2 + \|X\beta^* - Y\|^2.$$
	Let $X\in\mathbb{R}^{n\times d}, Y\in\mathbb{R}^n$. Further define $\beta^* = \operatorname{argmin}_{\beta\in R^d}\|X\beta-Y\|^2$. Then $$\|Y\|^2=\|X\beta^*\|^2 + \|X\beta^* - Y\|^2.$$
\end{linenomath*}
\end{theorem}

\begin{proof}
	The proof is left as an exercise.
\end{proof}

Sometimes figures help to illustrate a formalism. This is completely unrelated to Theorem \ref{thm:main}.

\section{Conclusion}
\label{conclusions}

Even after centuries of research in the field of data science, 
there is nothing more versatile than the useful theorem of chapter~\ref{main_part}. 
It is used everywhere and has led to the greatest and most intriguing results, cf. \cite{Someone03}. 
By the way, the book for the seminar \cite{SSBD14} is a great reference and should be cited.
Further literature can be found in the respective \emph{Bibliographic Remarks} sections and 
of course you are welcome to search and add your own references.

\paragraph*{Note:} Bib{\TeX} entries can often be found in the DBLP collection. 
Google Scholar also offers Bib\TeX~entries, which can be copied into the .bib file and may need some minor adjustments.
\bibliographystyle{abbrv}

\nolinenumbers
\footnotesize
\bibliography{bibliography}
\end{document}
